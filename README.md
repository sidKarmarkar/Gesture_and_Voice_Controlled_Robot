# Gesture & Voice Controlled Robot

This repository contains the code and documentation for a Voice and Gesture Controlled Robot using NodeMCU and Blynk platform.

## Project Overview

This project integrates voice recognition and gesture control mechanisms to create a robot that can be controlled through vocal instructions and predefined gestures.

### Key Objectives

- **Voice Control Integration**: Allows users to command the robot through vocal instructions.
- **Gesture Control Mechanism**: Utilizes motion sensor technologies for hands-free control.
- **NodeMCU and Blynk Platform**: Ensures seamless connectivity and real-time data exchange.
- **Wireless Connectivity**: Operates wirelessly for increased mobility.
- **User-Friendly Interface**: Provides a customizable dashboard for controlling and monitoring the robot.
- **Open-Source Development**: Encourages collaboration and further advancements in the field.

## Components/Technology Used

- **NodeMCU**
- **L294D Motor Drive**
- **Blynk API Platform**
- **IFTTT Software**
- **Google Assistant**

## Code

### NodeMCU Code

The NodeMCU code is located in `Code/Node_MCU.ino`.

### Python Code

The Python code for gesture recognition is located in `Code/Python.py`.

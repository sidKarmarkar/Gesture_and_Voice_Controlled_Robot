# Gesture & Voice Controlled Robot

This repository contains the code and documentation for a Voice and Gesture Controlled Robot using NodeMCU and Blynk platform.

## Project Overview

This project integrates voice recognition and gesture control mechanisms to create a robot that can be controlled through vocal instructions and predefined gestures.

### Key Objectives

- **Voice Control Integration**: Allows users to command the robot through vocal instructions.
- **Gesture Control Mechanism**: Utilizes motion sensor technologies for hands-free control.
- **NodeMCU and Blynk Platform**: Ensures seamless connectivity and real-time data exchange.
- **Wireless Connectivity**: Operates wirelessly for increased mobility.
- **User-Friendly Interface**: Provides a customizable dashboard for controlling and monitoring the robot.
- **Open-Source Development**: Encourages collaboration and further advancements in the field.

## Components/Technology Used

- **NodeMCU**
- **L294D Motor Drive**
- **Blynk API Platform**
- **IFTTT Software**
- **Google Assistant**

## Code

### NodeMCU Code

The NodeMCU code is located in `Code/NodeMCU_Code.ino`.

### Python Code

The Python code for gesture recognition is located in `Code/Python_Code.py`.

## Documentation

The full project report can be found in `Documentation/Report.pdf`.

## Authors

- Govind Kishore (20BEE0210)
- Siddharth Karmarkar (20BEE0212)
- Arihant Singh Samyal (20BEE0358)

## Acknowledgments

We extend our sincere gratitude to Dr. Vinodh Kumar E, our professor-in-charge, whose guidance and valuable insights guided us through the intricacies of robotics and technology.

## License

This project is licensed under the MIT License.
